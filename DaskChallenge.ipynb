{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from sklearn.linear_model import RidgeCV,LassoCV,ElasticNetCV\n",
    "\n",
    "\n",
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vif(x):\n",
    "    \"\"\"Utility for checking multicollinearity assumption\n",
    "    \n",
    "    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\n",
    "    :return: nothing is returned the VIFs are printed as a pandas series\n",
    "    \"\"\"\n",
    "    # Silence numpy FutureWarning about .ptp\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "    vifs = []\n",
    "    for i in range(x.shape[1]):\n",
    "        vif = variance_inflation_factor(x.values, i)\n",
    "        vifs.append(vif)\n",
    "\n",
    "    print(\"VIF results\\n-------------------------------\")\n",
    "    print(pd.Series(vifs, index=x.columns))\n",
    "    print(\"-------------------------------\\n\")\n",
    "    \n",
    "def eval_preds(y_true, y_pred,graph=False):\n",
    "    error = y_true - y_pred\n",
    "\n",
    "    rmse = np.sqrt((error ** 2).mean())\n",
    "    mae = error.abs().mean()\n",
    "    mape = (error / y_true).abs().mean()\n",
    "\n",
    "    print(f\"rmse {rmse}\")\n",
    "    print(f\"mae {mae}\")\n",
    "    print(f\"mape {mape}\")\n",
    "    \n",
    "    if graph==True:\n",
    "        line_pts = [y_true.min(), y_true.max()]\n",
    "        plt.scatter(y_true, y_pred)\n",
    "        plt.plot(line_pts, line_pts, c=\"red\", ls=\"--\", alpha=0.5)\n",
    "        plt.xlabel(\"Actual\")\n",
    "        plt.ylabel(\"Fit\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from dask import dataframe as dd \n",
    "from dask.distributed import Client, progress\n",
    "import joblib\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from category_encoders import LeaveOneOutEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "df = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=4, threads_per_worker=2, memory_limit='2GB')\n",
    "sd = dd.from_pandas(df, npartitions=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with missing values\n",
    "drop_cols=[]\n",
    "for col in sd.columns:\n",
    "    if df[col].isna().mean()>.4:\n",
    "        drop_cols=drop_cols+[col]\n",
    "df_clean=sd.drop(columns=drop_cols).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dask, you need to use mask instead of loc \n",
    "df_clean['secondflrexists']=0\n",
    "df_clean['secondflrexists']=df_clean['secondflrexists'].mask(df_clean['secondflrsf']>0,1) #can prob drop 2nd fl sq ft\n",
    "df_clean['yrsbltqared']=df_clean['yearbuilt']*df_clean['yearbuilt']\n",
    "df_clean['agebuilt']=df_clean['yrsold']-df_clean['yearbuilt']\n",
    "df_clean['ageremodeled']=df_clean['yrsold']-df_clean['yearremodadd']\n",
    "df_clean['agebuiltsquared']=df_clean['agebuilt']*df_clean['agebuilt']\n",
    "df_clean['agebuiltcubed']=df_clean['agebuilt']*df_clean['agebuilt']*df_clean['agebuilt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['overallqualsquared']=df_clean['overallqual']*df_clean['overallqual']\n",
    "df_clean['overallqualcubed']=df_clean['overallqual']*df_clean['overallqual']*df_clean['overallqual']\n",
    "df_clean['grlivareasquared']=df_clean['grlivarea']*df_clean['grlivarea']\n",
    "df_clean['ageremodeledsquared']=df_clean['ageremodeled']*df_clean['ageremodeled']\n",
    "df_clean['totalsf']=df_clean['totalbsmtsf']+df_clean['grlivarea']\n",
    "df_clean['lotareasquared']=df_clean['lotarea']*df_clean['lotarea']\n",
    "\n",
    "#making partial,centralair and the neighborhood a binary variable\n",
    "niceneighborhoods=['NridgHt', 'NoRidge', 'Somerst', 'Timber', 'Veenker', 'StoneBr']\n",
    "goodneighborhoods=['ClearCr','Crawfor','CollgCr','Gilbert','Blmngtn','SawyerW','NWAmes']\n",
    "\n",
    "df_clean['nicehood']=0\n",
    "df_clean['nicehood']=df_clean['nicehood'].mask(df_clean.neighborhood.isin(niceneighborhoods),1)\n",
    "# df_clean['hoodrank']=0\n",
    "# df_clean.loc[df_clean.neighborhood.isin(goodneighborhoods),'hoodrank']=1\n",
    "# df_clean.loc[df_clean.neighborhood.isin(niceneighborhoods),'hoodrank']=2\n",
    "df_clean['goodhood']=0\n",
    "df_clean['goodhood']=df_clean['goodhood'].mask(df_clean.neighborhood.isin(goodneighborhoods),1)\n",
    "\n",
    "#Making binary cats ints\n",
    "# df_clean['sale_partial']=0\n",
    "# df_clean.loc[df_clean.salecondition=='Partial','sale_partial']=1\n",
    "df_clean['centralairint']=0\n",
    "df_clean['centralairint']=df_clean['centralairint'].mask(df_clean.centralair=='Y',1)\n",
    "# df_clean['remodeled']=1\n",
    "# df_clean.loc[df_clean.agebuilt==df_clean.ageremodeled,'remodeled']=0\n",
    "# df_clean['pavedDW']=0\n",
    "# df_clean.loc[df_clean.paveddrive=='P','pavedDW']=1\n",
    "df_clean['haspool']=0\n",
    "df_clean['haspool']=df_clean['haspool'].mask(df_clean.poolarea>0,1)\n",
    "\n",
    "#Making some interaction variables:\n",
    "df_clean['nicehood_quality']=df_clean['overallqual']*df_clean['nicehood']\n",
    "# df_clean['goodhood_quality']=df_clean['overallqual']*df_clean['goodhood']\n",
    "df_clean['nicehood_totalsf']=df_clean['totalsf']*df_clean['nicehood']\n",
    "df_clean['goodhood_totalsf']=df_clean['totalsf']*df_clean['goodhood']\n",
    "\n",
    "df_clean['totaloutside']=(df_clean['enclosedporch']+df_clean['wooddecksf']+ \n",
    "                          df_clean['openporchsf']+df_clean['threessnporch']+\n",
    "                          df_clean['screenporch']#+df_clean['poolarea']\n",
    "                         )\n",
    "df_clean['totaloutside_quality']=df_clean['overallqual']*df_clean['totaloutside']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=['nicehood','goodhood','centralairint','salepartial']\n",
    "num_cols=['overallqual',\n",
    "          'overallqualsquared',\n",
    "          'overallqualcubed',\n",
    "          'grlivarea',\n",
    "          'totalbsmtsf',\n",
    "          'garagearea',\n",
    "          'lotarea',\n",
    "          'lotareasquared',\n",
    "          'ageremodeled',\n",
    "          'ageremodeledsquared',\n",
    "          'agebuilt',\n",
    "          'agebuiltsquared',\n",
    "          'bedroomabvgr']\n",
    "\n",
    "X = df_clean[['overallqual',\n",
    "              'overallqualsquared',#\n",
    "              'overallqualcubed',#\n",
    "              'grlivarea',\n",
    "              'grlivareasquared',#\n",
    "               'totalbsmtsf',\n",
    "               'garagearea', \n",
    "               'lotarea',\n",
    "              'lotareasquared',\n",
    "              'neighborhood',\n",
    "               'ageremodeled',\n",
    "               'ageremodeledsquared',\n",
    "               'agebuilt',\n",
    "               'agebuiltsquared',\n",
    "              'centralairint',\n",
    "              'bedroomabvgr',#\n",
    "              'nicehood_totalsf',\n",
    "              'goodhood_totalsf',\n",
    "              'totaloutside',\n",
    "              'secondflrexists',#\n",
    "              'haspool',\n",
    "              ]]\n",
    "y = df_clean['saleprice']\n",
    "y_log=np.log(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I had to use compute here because I didn't have dask_ml\n",
    "X_train, X_test, y_log_train, y_log_test=train_test_split(X.compute(),y_log.compute(),test_size=.2,random_state=1)\n",
    "# X_train = dd.from_pandas(X_train, npartitions=3)\n",
    "# X_test = dd.from_pandas(X_test, npartitions=3)\n",
    "# y_log_test = dd.from_pandas(y_log_test, npartitions=3)\n",
    "# y_log_train = dd.from_pandas(y_log_train, npartitions=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesmoss/opt/anaconda3/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "encoder = LeaveOneOutEncoder(cols=[\"neighborhood\"])\n",
    "X_train=encoder.fit_transform(X_train, y_log_train)\n",
    "X_test=encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    9.9s finished\n"
     ]
    }
   ],
   "source": [
    "grid = {\"max_depth\": [5,6,8], \"n_estimators\": [50],'min_samples_leaf':[5, 10]}\n",
    "model = GridSearchCV(\n",
    "    RandomForestRegressor(),\n",
    "    param_grid=grid,\n",
    "    cv=4,\n",
    "    #     scoring=make_scorer(f1_score),\n",
    "#     scoring=make_scorer(roc_auc_score),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    model.fit(X_train, y_log_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918821199576981\n",
      "0.8485988119939958\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_train, y_log_train))\n",
    "print(model.score(X_test, y_log_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
