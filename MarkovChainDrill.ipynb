{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, do some data preprocessing to clean up the data as necessary. You can use your solution to the assignment of the Text preprocessing checkpoint.\n",
    "2. Train a Markov chain model by using only the negative sentiment tweets. Generate some random sentences. Do the generated sentences exhibit the same negative sentiment?\n",
    "3. Repeat the previous task, but this time, use only the positive sentiment tweets. Generate some random sentences and observe whether they exhibit positive sentiment or not.\n",
    "4. Now, train your Markov chain model using all of the tweets. Generate some random sentences. Can you say something systematic about the sentiments of the generated tweets?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import spacy\n",
    "import markovify\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'twitter_sentiment'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "tweets_df = pd.read_sql_query('select * from twitter',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "# below is necessary to avoid memory error of SpaCy\n",
    "nlp.max_length = 20000000\n",
    "\n",
    "# all the processing work is done below, so it may take a while\n",
    "twitter_doc = nlp(\" \".join(tweets_df.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         neutral\n",
       "1        positive\n",
       "2         neutral\n",
       "3        negative\n",
       "4        negative\n",
       "           ...   \n",
       "14635    negative\n",
       "14636    negative\n",
       "14637     neutral\n",
       "14638    negative\n",
       "14639     neutral\n",
       "Name: airline_sentiment, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.airline_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the processing work is done below, so it may take a while\n",
    "twitter_negative_doc = nlp(\" \".join(tweets_df[tweets_df[\"airline_sentiment\"]==\"negative\"].text))\n",
    "\n",
    "tweet_negative_sents = \" \".join([sent.text for sent in twitter_negative_doc.sents if len(sent.text) > 1])\n",
    "\n",
    "tweet_negative_generator = markovify.Text(tweet_negative_sents, state_size = 3)\n",
    "\n",
    "# three randomly generated negative sentences\n",
    "for i in range(20):\n",
    "    print(tweet_negative_generator.make_sentence(tries=100))\n",
    "\n",
    "# three randomly-generated negative sentences of no more than 100 characters\n",
    "for i in range(20):\n",
    "    print(tweet_negative_generator.make_short_sentence(100, tries=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the processing work is done below, so it may take a while\n",
    "twitter_positive_doc = nlp(\" \".join(tweets_df[tweets_df[\"airline_sentiment\"]==\"positive\"].text))\n",
    "\n",
    "tweet_positive_sents = \" \".join([sent.text for sent in twitter_positive_doc.sents if len(sent.text) > 1])\n",
    "\n",
    "tweet_positive_generator = markovify.Text(tweet_positive_sents, state_size = 3)\n",
    "\n",
    "# three randomly generated sentences\n",
    "for i in range(20):\n",
    "    print(tweet_positive_generator.make_sentence(tries=100))\n",
    "\n",
    "# three randomly-generated sentences of no more than 100 characters\n",
    "for i in range(20):\n",
    "    print(tweet_positive_generator.make_short_sentence(100, tries=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the processing work is done below, so it may take a while\n",
    "twitter_doc = nlp(\" \".join(tweets_df.text))\n",
    "\n",
    "tweet_sents = \" \".join([sent.text for sent in twitter_doc.sents if len(sent.text) > 1])\n",
    "\n",
    "tweet_generator = markovify.Text(tweet_sents, state_size = 3)\n",
    "\n",
    "# three randomly generated sentences\n",
    "for i in range(20):\n",
    "    print(tweet_generator.make_sentence(tries=100))\n",
    "\n",
    "# three randomly-generated sentences of no more than 100 characters\n",
    "for i in range(20):\n",
    "    print(tweet_generator.make_short_sentence(100, tries=100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
