{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from sklearn.linear_model import RidgeCV,LassoCV,ElasticNetCV\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n",
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vif(x):\n",
    "    \"\"\"Utility for checking multicollinearity assumption\n",
    "    \n",
    "    :param x: input features to check using VIF. This is assumed to be a pandas.DataFrame\n",
    "    :return: nothing is returned the VIFs are printed as a pandas series\n",
    "    \"\"\"\n",
    "    # Silence numpy FutureWarning about .ptp\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "    vifs = []\n",
    "    for i in range(x.shape[1]):\n",
    "        vif = variance_inflation_factor(x.values, i)\n",
    "        vifs.append(vif)\n",
    "\n",
    "    print(\"VIF results\\n-------------------------------\")\n",
    "    print(pd.Series(vifs, index=x.columns))\n",
    "    print(\"-------------------------------\\n\")\n",
    "    \n",
    "def eval_preds(y_true, y_pred,graph=False):\n",
    "    error = y_true - y_pred\n",
    "\n",
    "    rmse = np.sqrt((error ** 2).mean())\n",
    "    mae = error.abs().mean()\n",
    "    mape = (error / y_true).abs().mean()\n",
    "\n",
    "    print(f\"rmse {rmse}\")\n",
    "    print(f\"mae {mae}\")\n",
    "    print(f\"mape {mape}\")\n",
    "    \n",
    "    if graph==True:\n",
    "        line_pts = [y_true.min(), y_true.max()]\n",
    "        plt.scatter(y_true, y_pred)\n",
    "        plt.plot(line_pts, line_pts, c=\"red\", ls=\"--\", alpha=0.5)\n",
    "        plt.xlabel(\"Actual\")\n",
    "        plt.ylabel(\"Fit\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset and manipulating the variables\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "df = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()\n",
    "\n",
    "#deal with missing values\n",
    "drop_cols=[]\n",
    "for col in df.columns:\n",
    "    if df[col].isna().mean()>.4:\n",
    "        drop_cols=drop_cols+[col]\n",
    "df_clean=df.drop(columns=drop_cols).dropna()\n",
    "\n",
    "#manipulate features, ones I don't use are commented out\n",
    "df_clean['secondflrexists']=0\n",
    "df_clean.loc[df['secondflrsf']>0,'secondflrexists']=1 #can prob drop 2nd fl sq ft\n",
    "df_clean['yrsbltqared']=df_clean['yearbuilt']*df_clean['yearbuilt']\n",
    "df_clean['agebuilt']=df_clean['yrsold']-df_clean['yearbuilt']\n",
    "df_clean['ageremodeled']=df_clean['yrsold']-df_clean['yearremodadd']\n",
    "df_clean['agebuiltsquared']=df_clean['agebuilt']*df_clean['agebuilt']\n",
    "df_clean['agebuiltcubed']=df_clean['agebuilt']*df_clean['agebuilt']*df_clean['agebuilt']\n",
    "\n",
    "# df_clean['logagebuilt']=np.log1p(df_clean['agebuilt'])\n",
    "# df_clean['logageremodeled']=np.log1p(df_clean['ageremodeled'])\n",
    "\n",
    "# df_clean['garageage']=df_clean['yrsold']-df_clean['garageyrblt']\n",
    "# df_clean['garageagesquared']=df_clean['garageage']**2\n",
    "\n",
    "####\n",
    "df_clean['overallqualsquared']=df_clean['overallqual']*df_clean['overallqual']\n",
    "df_clean['overallqualcubed']=df_clean['overallqual']*df_clean['overallqual']*df_clean['overallqual']\n",
    "#df_clean['logqualsquared']=np.log(df_clean['overallqualsquared'])\n",
    "# df_clean['logqual']=np.log(df_clean['overallqual'])\n",
    "# df_clean['squaredlogqual']=df_clean['logqual']*df_clean['logqual']\n",
    "\n",
    "df_clean['grlivareasquared']=df_clean['grlivarea']*df_clean['grlivarea']\n",
    "# df_clean['loggrlivarea']=np.log(df_clean['grlivarea'])\n",
    "# df_clean['squaredlogarea']=df_clean['loggrlivarea']*df_clean['loggrlivarea']\n",
    "\n",
    "\n",
    "df_clean['ageremodeledsquared']=df_clean['ageremodeled']*df_clean['ageremodeled']\n",
    "# df_clean['ageremodeledcubed']=df_clean['ageremodeled']*df_clean['ageremodeled']\n",
    "\n",
    "df_clean['totalsf']=df_clean['totalbsmtsf']+df_clean['grlivarea']\n",
    "# df_clean['qual_totalsf']=df_clean['totalsf']*df_clean['overallqual']\n",
    "\n",
    "df_clean['lotareasquared']=df_clean['lotarea']*df_clean['lotarea']\n",
    "\n",
    "#making partial,centralair and the neighborhood a binary variable\n",
    "niceneighborhoods=['NridgHt', 'NoRidge', 'Somerst', 'Timber', 'Veenker', 'StoneBr']\n",
    "goodneighborhoods=['ClearCr','Crawfor','CollgCr','Gilbert','Blmngtn','SawyerW','NWAmes']\n",
    "\n",
    "df_clean['nicehood']=0\n",
    "df_clean.loc[df_clean.neighborhood.isin(niceneighborhoods),'nicehood']=1\n",
    "df_clean['hoodrank']=0\n",
    "df_clean.loc[df_clean.neighborhood.isin(goodneighborhoods),'hoodrank']=1\n",
    "df_clean.loc[df_clean.neighborhood.isin(niceneighborhoods),'hoodrank']=2\n",
    "df_clean['goodhood']=0\n",
    "df_clean.loc[df_clean.neighborhood.isin(goodneighborhoods),'goodhood']=1\n",
    "\n",
    "#Making binary cats ints\n",
    "df_clean['sale_partial']=0\n",
    "df_clean.loc[df_clean.salecondition=='Partial','sale_partial']=1\n",
    "df_clean['centralairint']=0\n",
    "df_clean.loc[df_clean.centralair=='Y','centralairint']=1\n",
    "# df_clean['pavedstreet']=0\n",
    "# df_clean.loc[df_clean.salecondition=='Pave','pavedstreet']=1\n",
    "df_clean['remodeled']=1\n",
    "df_clean.loc[df_clean.agebuilt==df_clean.ageremodeled,'remodeled']=0\n",
    "df_clean['pavedDW']=0\n",
    "df_clean.loc[df_clean.paveddrive=='P','pavedDW']=1\n",
    "df_clean['haspool']=0\n",
    "df_clean.loc[df_clean.poolarea>0,'haspool']=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Making some interaction variables:\n",
    "df_clean['nicehood_quality']=df_clean['overallqual']*df_clean['nicehood']\n",
    "df_clean['goodhood_quality']=df_clean['overallqual']*df_clean['goodhood']\n",
    "df_clean['nicehood_totalsf']=df_clean['totalsf']*df_clean['nicehood']\n",
    "df_clean['goodhood_totalsf']=df_clean['totalsf']*df_clean['goodhood']\n",
    "\n",
    "df_clean['totaloutside']=(df_clean['enclosedporch']+df_clean['wooddecksf']+ \n",
    "                          df_clean['openporchsf']+df_clean['threessnporch']+\n",
    "                          df_clean['screenporch']#+df_clean['poolarea']\n",
    "                         )\n",
    "df_clean['totaloutside_quality']=df_clean['overallqual']*df_clean['totaloutside']\n",
    "\n",
    "#one hot encoding neighborhood\n",
    "#df_clean = pd.concat([df_clean,pd.get_dummies(df_clean.neighborhood, prefix=\"hood\", drop_first=True)], axis=1)\n",
    "df_clean = pd.concat([df_clean,pd.get_dummies(df_clean.kitchenqual, prefix=\"kitchen\", drop_first=True)], axis=1)\n",
    "df_clean = pd.concat([df_clean,pd.get_dummies(df_clean.bldgtype, prefix=\"buildingtype\", drop_first=True)], axis=1)\n",
    "#could try the other type of encoding instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping outliers of high leveridge\n",
    "df_clean=df_clean.drop([314,523,1298,452])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the feature selection and OLS model\n",
    "\n",
    "# Right hashtag indicates vars I'm iffy on\n",
    "cat_cols=['nicehood','goodhood','centralairint','salepartial']\n",
    "num_cols=['overallqual',\n",
    "          'overallqualsquared',\n",
    "          'overallqualcubed',\n",
    "          'grlivarea',\n",
    "          'grlivareasquared',\n",
    "          'totalbsmtsf',\n",
    "          'garagearea',\n",
    "          'lotarea',\n",
    "          'lotareasquared',\n",
    "          'ageremodeled',\n",
    "          'ageremodeledsquared',\n",
    "          'agebuilt',\n",
    "          'agebuiltsquared',\n",
    "          'bedroomabvgr',\n",
    "         'nicehood_totalsf',\n",
    "          'goodhood_totalsf',\n",
    "          'totaloutside'\n",
    "          \n",
    "         ]\n",
    "\n",
    "cat_cols2=['neighborhood']\n",
    "\n",
    "X = df_clean[['overallqual',\n",
    "              'overallqualsquared',#\n",
    "              'overallqualcubed',#\n",
    "              'grlivarea',\n",
    "              'grlivareasquared',#\n",
    "#               'loggrlivarea',#\n",
    "               'totalbsmtsf',\n",
    "               #'totalsf',#\n",
    "               'garagearea', \n",
    "               'lotarea',\n",
    "              'lotareasquared',\n",
    "#               'nicehood',\n",
    "#               'goodhood',\n",
    "#               'hoodrank',#\n",
    "              'neighborhood',\n",
    "               'ageremodeled',\n",
    "               'ageremodeledsquared',\n",
    "#               'ageremodeledcubed',#\n",
    "#               'logageremodeled',##\n",
    "               'agebuilt',\n",
    "               'agebuiltsquared',\n",
    "#               'logagebuilt',##\n",
    "               'sale_partial',#\n",
    "              'centralairint',\n",
    "#               'newsale',#\n",
    "              'bedroomabvgr',#\n",
    "#                'yrsold',\n",
    "#               'nicehood_quality',\n",
    "#               'goodhood_quality',\n",
    "              'nicehood_totalsf',\n",
    "              'goodhood_totalsf',\n",
    "              'totaloutside',\n",
    "#               'pavedDW',##\n",
    "              'secondflrexists',#\n",
    "#               'remodeled'##\n",
    "#               'poolarea'##\n",
    "              'haspool',\n",
    "#               'totaloutside_quality'\n",
    "#               'kitchen_Fa',#\n",
    "#               'kitchen_Gd',#\n",
    "#               'kitchen_TA',#\n",
    "#               'pavedDW'##\n",
    "#               'buildingtype_2fmCon',\n",
    "#               'buildingtype_Duplex',\n",
    "#               'buildingtype_Twnhs',\n",
    "#               'buildingtype_TwnhsE',\n",
    "              ]]\n",
    "y = df_clean.saleprice\n",
    "y_log=np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "X_train, X_test, y_log_train, y_log_test=train_test_split(X,y_log,test_size=.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LeaveOneOutEncoder(cols=[\"neighborhood\"])\n",
    "X_train=encoder.fit_transform(X_train, y_log_train)\n",
    "X_test=encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=10,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=15, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(min_samples_leaf=15, max_depth=10)\n",
    "model.fit(X_train, y_log_train)\n",
    "# cross_val_score(model, X_train, y_log_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log_preds=model.predict(X_test)\n",
    "y_log_train_preds=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8705890039844243\n",
      "0.7857801079957827\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_train, y_log_train))\n",
    "print(model.score(X_test, y_log_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, the KNN model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.06094813346862793 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y_log, test_size=.2, random_state=1 )\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"encode_cats\", LeaveOneOutEncoder(), cat_cols2),\n",
    "        (\"scale\", StandardScaler(), num_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('KNN',KNeighborsRegressor())\n",
    "    ],\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.20643186569213867 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# model= RandomForestRegressor(min_samples_leaf=20, max_depth=8, n_estimators=50)\n",
    "# model.fit(X_train, y_train)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898837834520026\n",
      "0.85788712389569\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.score(X_train, y_train))\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN model did much better than the linear version, I suspect because some of numeric variables don't have a linear relationship to the target variable. Also some variables really clump at 0, like the interactions with pool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
