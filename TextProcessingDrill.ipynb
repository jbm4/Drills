{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the data preprocessing techniques that you learned here to the Cornell Movie--Dialogs Corpus data. You'll use this dataset when developing a chatbot in an upcoming checkpoint. Access the dataset from the Thinkful database using the following credentials:\n",
    "\n",
    "* Apply the data preprocessing techniques that you learned here to Twitter US Airline Sentiment data. You'll use this dataset when generating sentences in an upcoming checkpoint. You should access the dataset from the Thinkful database using the following credentials:\n",
    "\n",
    "* Note: When parsing the data using spaCy, you may run into some memory issues, even in Google Colaboratory. If you're having memory issues, try parsing your text as follows:\n",
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "\n",
    "nlp.max_length = 20000000\n",
    "\n",
    "doc = nlp(the_dialogs_come_here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cornell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'cornell_movie_dialogs'\n",
    "\n",
    "engine = pd.read_sql_table('dialogs','postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "#dialogue = engine.execute('SELECT * FROM dialogs')\n",
    "\n",
    "#engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue=engine.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue.dialogs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#preprocessing steps: tokenization, lemmatization, part of speech?, \n",
    "\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "for index, row in dialogue[:10].iterrows():\n",
    "    sentence=row['dialogs']\n",
    "    doc=nlp(sentence)\n",
    "    for token in doc:\n",
    "        print(token.text)\n",
    "        #print(token.pos_)\n",
    "        #print(token.dep)\n",
    "        #lemmatization\n",
    "        #stop word removal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seems like she could get a date easy enough..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('Seems like she could get a date easy enough...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "def processing(line):\n",
    "    tokenized=nlp(line)\n",
    "    no_stops_punct=[token for token in tokenized if not token.is_stop if not token.is_punct if str(token).strip()]\n",
    "    lemmas=[word.lemma_ for word in no_stops_punct]\n",
    "    return lemmas\n",
    "#dialogue['clean']=dialogue.dialogs.apply(lambda x: processing(x))\n",
    "dialogue.head().dialogs.apply(lambda x: processing(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "0         [quick, Roxanne, Korrine, Andrew, Barrett, hav...\n",
       "1                       [think, start, pronunciation, okay]\n",
       "2                                      [hacking, gag, spit]\n",
       "3         [okay, about, try, french, cuisine, Saturday, ...\n",
       "4                                               [ask, cute]\n",
       "                                ...                        \n",
       "304441                                                  NaN\n",
       "304442                                                  NaN\n",
       "304443                                                  NaN\n",
       "304444                                                  NaN\n",
       "304445                                                  NaN\n",
       "Name: clean, Length: 304446, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue.clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'twitter_sentiment'\n",
    "airline = pd.read_sql_table('twitter','postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline.head().text.apply(lambda x: processing(x))\n",
    "airline['clean']=airline.text.apply(lambda x: processing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornell='http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html'\n",
    "\n",
    "sentiment='https://www.kaggle.com/crowdflower/twitter-airline-sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(airline, open( \"/Users/jamesmoss/Documents/GitHub/Notes and Exercises/IndividualExercises/Week15/airline.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
